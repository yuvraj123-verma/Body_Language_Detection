{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "285ec1ff",
   "metadata": {},
   "source": [
    "## 0. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd2c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae6377",
   "metadata": {},
   "source": [
    "## 1. Make some Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6935ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv.VideoCapture(0)\n",
    "# with mp_holistic.Holistic(min_detection_confidence= 0.5, min_tracking_confidence= 0.5) as holistic:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor the image to RGB\n",
    "#         image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         # Make Detection \n",
    "#         results = holistic.process(image)\n",
    "        \n",
    "#         # Recolor the RGB back to BGR\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "#         # Draw face Landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 1, circle_radius= 2),\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 1, circle_radius= 2))\n",
    "                                  \n",
    "#         # Draw Right Hand Landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 2, circle_radius= 4),\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 2, circle_radius= 2))\n",
    "                                  \n",
    "#         # Draw Left Hand Landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 2, circle_radius= 4),\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 2, circle_radius= 2))\n",
    "                                  \n",
    "#         # Draw Pose Landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 2, circle_radius= 4),\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 2, circle_radius= 2))\n",
    "                                  \n",
    "                                  \n",
    "                                  \n",
    "#         cv.imshow('Frame', image)\n",
    "        \n",
    "#         if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "# cap.release()\n",
    "# cv.destroyAllWindows()                                  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6755c4",
   "metadata": {},
   "source": [
    "## 2. Capture Landmarks & Export To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47d4432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45518d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_coords = len(results.face_landmarks.landmark)+len(results.pose_landmarks.landmark)\n",
    "# num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9baa4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmarks = ['class']\n",
    "# for val in range(1, num_coords+1):\n",
    "#     landmarks+=[f'x{val}', f'y{val}', f'z{val}', f'v{val}']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594afb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('coords.csv', mode = 'w', newline= '') as f:\n",
    "#     csv_writer = csv.writer(f, delimiter = ',',quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "#     csv_writer.writerow(landmarks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "530fa148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_name = 'Victorious'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01125a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv.VideoCapture(0)\n",
    "# with mp_holistic.Holistic(min_detection_confidence= 0.5, min_tracking_confidence= 0.5) as holistic:\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor the image to RGB\n",
    "#         image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "#         image.flags.writeable = False\n",
    "        \n",
    "#         # Make Detection \n",
    "#         results = holistic.process(image)\n",
    "        \n",
    "#         # Recolor the RGB back to BGR\n",
    "#         image.flags.writeable = True\n",
    "#         image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # 1. Draw face Landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 1, circle_radius= 1),\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 1, circle_radius= 1))\n",
    "                                  \n",
    "#         # 2. Right Hand Landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 2, circle_radius= 4),\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 2, circle_radius= 2))\n",
    "                                  \n",
    "#         # 3. Left Hand Landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 2, circle_radius= 4),\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 2, circle_radius= 2))\n",
    "                                  \n",
    "#         # 4. Pose Landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 2, circle_radius= 4),\n",
    "#                                  mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 2, circle_radius= 2))\n",
    "                                  \n",
    "#         # Export Coordinates\n",
    "#         try:\n",
    "            \n",
    "#             # Pose landmarks\n",
    "#             pose = results.pose_landmarks.landmark\n",
    "#             pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "#             # Face Landmarks\n",
    "#             face = results.face_landmarks.landmark\n",
    "#             face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "#             # concate rows\n",
    "#             row = pose_row+face_row\n",
    "#             # Append class name\n",
    "#             row.insert(0, class_name)\n",
    "            \n",
    "#             # Both pose and face landmarks Exported into CSV file \n",
    "#             with open('coords.csv', mode = 'a', newline= '') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter = ',',quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row)\n",
    "\n",
    "            \n",
    "#         except:\n",
    "#             pass\n",
    "                                  \n",
    "#         cv.imshow('Frame', image)\n",
    "        \n",
    "#         if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "# cap.release()\n",
    "# cv.destroyAllWindows()                                  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0823a7f",
   "metadata": {},
   "source": [
    "## 3. Train Custom Model Using SciKit Learn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d547b11b",
   "metadata": {},
   "source": [
    "## 3.1 Read in Collected Data and Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0c0166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efe741ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c679620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('class', axis = 1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba26cef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state= 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a6b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fe690e6",
   "metadata": {},
   "source": [
    "## 3.2 Train Machine Learning Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ab3149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3c5b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = {\n",
    "    'lr' : make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc' : make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf' : make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb' : make_pipeline(StandardScaler(), GradientBoostingClassifier())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fc994ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = {}\n",
    "for algo, pipeline in pipeline.items():\n",
    "    model = pipeline.fit(x_train, y_train)\n",
    "    fit_model[algo] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8244c0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7234eb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Victorious', 'Victorious', 'Sad', 'Victorious', 'Happy', 'Happy',\n",
       "       'Sad', 'Sad', 'Sad', 'Victorious', 'Sad', 'Happy', 'Victorious',\n",
       "       'Happy', 'Happy', 'Happy', 'Victorious', 'Victorious',\n",
       "       'Victorious', 'Victorious', 'Sad', 'Happy', 'Happy', 'Sad',\n",
       "       'Victorious', 'Sad', 'Happy', 'Sad', 'Sad', 'Sad', 'Happy', 'Sad',\n",
       "       'Happy', 'Sad', 'Victorious', 'Sad', 'Victorious', 'Victorious',\n",
       "       'Victorious', 'Happy', 'Sad', 'Happy', 'Happy', 'Sad', 'Sad',\n",
       "       'Sad', 'Victorious', 'Victorious', 'Victorious', 'Happy', 'Happy',\n",
       "       'Happy', 'Sad', 'Victorious', 'Sad', 'Happy', 'Victorious',\n",
       "       'Happy', 'Sad', 'Victorious', 'Happy', 'Sad', 'Victorious',\n",
       "       'Happy', 'Victorious', 'Happy', 'Happy', 'Sad', 'Happy', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Sad', 'Victorious', 'Sad', 'Happy',\n",
       "       'Sad'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model['gb'].predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cbc393",
   "metadata": {},
   "source": [
    "## 3.3 Evaluate and Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362d9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "257574e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.0\n",
      "rc 1.0\n",
      "rf 1.0\n",
      "gb 1.0\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_model.items():\n",
    "    yhat = model.predict(x_test)\n",
    "    print(algo, accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a764243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_model['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f366e7",
   "metadata": {},
   "source": [
    "## 4. Make Detection with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3693d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('body_language.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c1c9d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74ed743f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victorious [0.   0.08 0.92]\n",
      "Victorious [0.   0.08 0.92]\n",
      "Victorious [0.   0.09 0.91]\n",
      "Victorious [0.   0.08 0.92]\n",
      "Victorious [0.   0.11 0.89]\n",
      "Victorious [0.   0.13 0.87]\n",
      "Victorious [0.  0.1 0.9]\n",
      "Victorious [0.   0.08 0.92]\n",
      "Victorious [0.   0.11 0.89]\n",
      "Victorious [0.   0.11 0.89]\n",
      "Victorious [0.   0.09 0.91]\n",
      "Victorious [0.   0.08 0.92]\n",
      "Victorious [0.   0.12 0.88]\n",
      "Victorious [0.   0.06 0.94]\n",
      "Victorious [0.   0.06 0.94]\n",
      "Victorious [0.   0.06 0.94]\n",
      "Victorious [0.   0.06 0.94]\n",
      "Victorious [0.  0.1 0.9]\n",
      "Victorious [0.   0.04 0.96]\n",
      "Victorious [0.   0.03 0.97]\n",
      "Victorious [0.   0.03 0.97]\n",
      "Victorious [0.   0.03 0.97]\n",
      "Victorious [0.   0.08 0.92]\n",
      "Victorious [0.   0.29 0.71]\n",
      "Victorious [0.   0.47 0.53]\n",
      "Victorious [0.   0.34 0.66]\n",
      "Victorious [0.   0.28 0.72]\n",
      "Victorious [0.   0.22 0.78]\n",
      "Victorious [0.   0.22 0.78]\n",
      "Victorious [0.   0.21 0.79]\n",
      "Victorious [0.   0.21 0.79]\n",
      "Victorious [0.   0.21 0.79]\n",
      "Victorious [0.   0.15 0.85]\n",
      "Victorious [0.   0.15 0.85]\n",
      "Victorious [0.   0.41 0.59]\n",
      "Victorious [0.   0.42 0.58]\n",
      "Victorious [0.   0.49 0.51]\n",
      "Victorious [0.   0.47 0.53]\n",
      "Sad [0.   0.55 0.45]\n",
      "Victorious [0.   0.33 0.67]\n",
      "Sad [0.01 0.55 0.44]\n",
      "Sad [0.   0.67 0.33]\n",
      "Sad [0.01 0.56 0.43]\n",
      "Victorious [0.01 0.38 0.61]\n",
      "Victorious [0.01 0.22 0.77]\n",
      "Victorious [0.01 0.1  0.89]\n",
      "Victorious [0.01 0.13 0.86]\n",
      "Victorious [0.01 0.1  0.89]\n",
      "Victorious [0.01 0.19 0.8 ]\n",
      "Victorious [0.01 0.2  0.79]\n",
      "Victorious [0.01 0.28 0.71]\n",
      "Victorious [0.01 0.32 0.67]\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence= 0.5, min_tracking_confidence= 0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor the image to RGB\n",
    "        image = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Make Detection \n",
    "        results = holistic.process(image)\n",
    "        \n",
    "        # Recolor the RGB back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # 1. Draw face Landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 1, circle_radius= 1),\n",
    "                                 mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 1, circle_radius= 1))\n",
    "                                  \n",
    "        # 2. Right Hand Landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 2, circle_radius= 4),\n",
    "                                 mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 2, circle_radius= 2))\n",
    "                                  \n",
    "        # 3. Left Hand Landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 2, circle_radius= 4),\n",
    "                                 mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 2, circle_radius= 2))\n",
    "                                  \n",
    "        # 4. Pose Landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color = (245, 65, 114), thickness= 2, circle_radius= 4),\n",
    "                                 mp_drawing.DrawingSpec(color = (245, 114, 65), thickness= 2, circle_radius= 2))\n",
    "                                  \n",
    "        # Export Coordinates\n",
    "        try:\n",
    "            \n",
    "            # Pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "            # Face Landmarks\n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "            # concate rows\n",
    "            row = pose_row+face_row\n",
    "            # Append class name\n",
    "\n",
    "            # MAke Detections\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "#             print(body_language_class, body_language_prob)\n",
    "            \n",
    "            # Get the EAR Coordiantes\n",
    "            coords = tuple(np.multiply(np.array((results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                                results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)),\n",
    "                                               [640, 480]).astype(int))\n",
    "            \n",
    "            cv.rectangle(image, (coords[0], coords[1]+5), (coords[0]+len(body_language_class)*20, coords[1]-30),\n",
    "                        (245, 117, 16), -1)\n",
    "            cv.putText(image, body_language_class, coords, cv.FONT_HERSHEY_SIMPLEX,\n",
    "                      0.5, (255, 255, 255), 2, cv.LINE_AA)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "                                  \n",
    "        cv.imshow('Frame', image)\n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv.destroyAllWindows()                                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c08cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
